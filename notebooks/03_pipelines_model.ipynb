{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41b0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# train_test_split: Para dividir el dataset en conjuntos de entrenamiento y validación.\n",
    "# Uso: Asegura que el modelo se evalúe en datos no vistos durante el entrenamiento.\n",
    "# GridSearchCV: Para la optimización de hiperparámetros de nuestro modelo y/o pipeline.\n",
    "# Uso: Busca sistemáticamente la mejor combinación de parámetros.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "# StandardScaler: Para estandarizar (escalar) las características numéricas.\n",
    "# Uso: Transforma los datos para que tengan media 0 y desviación estándar 1, útil para muchos algoritmos.\n",
    "# OneHotEncoder: Para convertir características categóricas (como 'Sex', 'Embarked') a formato numérico binario.\n",
    "# Uso: Permite que los modelos de ML trabajen con datos categóricos.\n",
    "# FunctionTransformer: Para integrar funciones personalizadas (como tus funciones de ingeniería de características)\n",
    "# Uso: Te permite usar tus funciones Python dentro del pipeline de Scikit-learn.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Uso: Para manejar los valores faltantes. Por ejemplo, rellenar 'Age' o 'Fare' con la media.\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Uso: Permite aplicar diferentes transformaciones a diferentes columnas del DataFrame.\n",
    "#      Es clave para nuestro pipeline, ya que tenemos columnas numéricas y categóricas.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Uso: La clase principal para construir tu pipeline. Encadena todos los pasos de preprocesamiento y el modelo.\n",
    "#      Esto garantiza que todas las transformaciones se apliquen consistentemente.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "# Uso: El algoritmo de Machine Learning que usaremos para nuestro modelo de clasificación binaria.\n",
    "#      Es un clasificador de conjunto robusto y de alto rendimiento.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# Uso: Para evaluar el rendimiento de nuestro modelo.\n",
    "# accuracy_score: La métrica principal para el concurso de Kaggle.\n",
    "# confusion_matrix: Muestra la cantidad de verdaderos positivos, negativos, falsos positivos y negativos.\n",
    "# classification_report: Proporciona precisión (precision), recall (sensibilidad) y F1-score por clase.\n",
    "\n",
    "# Librerías para visualización de datos (aunque en este notebook será más para mostrar resultados)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Uso: Para crear gráficos, como la matriz de confusión, para visualizar y entender los resultados del modelo.\n",
    "import joblib as jl\n",
    "\n",
    "# Configuración para gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "import numpy as np\n",
    "# Uso: Ajustes estéticos para que los gráficos se vean bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a398f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a001c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones iniciales: (1309, 11)\n",
      "Columnas iniciales: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "df_train_raw = pd.read_csv('../data/raw/train.csv')\n",
    "df_test_raw = pd.read_csv('../data/raw/test.csv')\n",
    "df_join_raw = pd.concat([df_train_raw.drop('Survived', axis=1), df_test_raw], ignore_index=True)\n",
    "temp_df = df_join_raw.copy()\n",
    "print(f'Dimensiones iniciales: {df_join_raw.shape}')\n",
    "print(f'Columnas iniciales: {list(df_join_raw.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d5eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado transformadores de ingenieria de features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_title_from_name(df):\n",
    "    df = df.copy()\n",
    "    def extract_title(name):\n",
    "        title_extracted = re.search(' ([A-Za-z]+)\\\\.', name)\n",
    "        if title_extracted:\n",
    "            return title_extracted.group(1)\n",
    "        return 'rare'\n",
    "    df['Title'] = df['Name'].apply(extract_title)\n",
    "    df = df.drop('Name', axis=1)\n",
    "    return df\n",
    "\n",
    "def classify_titles(df):\n",
    "    df = df.copy()\n",
    "    def classify(title):\n",
    "        if title in ('Countess', 'Lady', 'Jonkheer'):#3\n",
    "            return 3\n",
    "        elif title in ('Miss', 'Mrs', 'Mme', 'Mlle', 'Ms', 'Master', 'Dona'):#7\n",
    "            return 2\n",
    "        elif title in ('Dr', 'Rev', 'Col', 'Capt', 'Sir', 'Major', 'Don'):#7\n",
    "            return 1\n",
    "        return 0 #('Mr', 'rare')\n",
    "    df['Title'] = df['Title'].apply(classify)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_deck_from_cabin(df):\n",
    "    df = df.copy()\n",
    "    df['Cabin'] = df['Cabin'].fillna('Unknown')\n",
    "    df['Deck'] = df['Cabin'].transform(lambda x: x[0])\n",
    "    df = df.drop('Cabin', axis=1)\n",
    "    return df\n",
    "\n",
    "def get_agency_ticket_numbers_from_ticket(df):\n",
    "    df = df.copy()\n",
    "    def extract_prefix(ticket):\n",
    "        prefix_extracted = re.match(r'([A-Za-z\\./]+)', ticket)\n",
    "        if prefix_extracted:\n",
    "            return prefix_extracted.group(1).replace('.', '').replace('/', '').upper()\n",
    "        return 'NO_AGENCY'\n",
    "    df['Agency'] = df['Ticket'].apply(extract_prefix)\n",
    "    ticket_counts = df['Ticket'].value_counts()\n",
    "    df['TicketNumber'] = df['Ticket'].map(ticket_counts)\n",
    "    df = df.drop('Ticket', axis=1)\n",
    "    return df\n",
    "\n",
    "def familysize_isAlone_from_sibsp_parch(df):\n",
    "    df = df.copy()\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df = df.drop(['Parch', 'SibSp', 'PassengerId'], axis=1)\n",
    "    return df\n",
    "\n",
    "def reorgize_ticket_class(df):\n",
    "    df = df.copy()\n",
    "    def condition_class(ticket_class):\n",
    "        class_mapping = { 1: 2,  2: 1, 3: 0}\n",
    "        return class_mapping.get(ticket_class, 0)\n",
    "    df['Pclass'] = df['Pclass'].apply(condition_class)\n",
    "    return df\n",
    "\n",
    "def age_imputed_from_title_pclass(df):\n",
    "    df = df.copy()\n",
    "    df['Age'] = df.groupby(['Pclass', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Age'] = temp_df['Age'].fillna(temp_df['Age'].median())\n",
    "    return df\n",
    "\n",
    "feature_engineering_pipeline = Pipeline([\n",
    "    ('get_title', FunctionTransformer(get_title_from_name, validate=False)),\n",
    "    ('classify_title', FunctionTransformer(classify_titles, validate=False)),\n",
    "    ('get_deck', FunctionTransformer(get_deck_from_cabin, validate=False)),\n",
    "    ('get_agency', FunctionTransformer(get_agency_ticket_numbers_from_ticket, validate=False)),\n",
    "    ('familySize', FunctionTransformer(familysize_isAlone_from_sibsp_parch, validate=False)),\n",
    "    ('reorganize_pclass', FunctionTransformer(reorgize_ticket_class, validate=False)),\n",
    "    ('imputer_custom_age', FunctionTransformer(age_imputed_from_title_pclass, validate=False))\n",
    "])\n",
    "feature_engineering_pipeline.set_output(transform='pandas')\n",
    "print('Cargado transformadores de ingenieria de features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ee625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessor created\n"
     ]
    }
   ],
   "source": [
    "numeric_features = ['Age', 'Fare', 'TicketNumber', 'FamilySize', 'Pclass', 'Title']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['Embarked', 'Deck', 'Agency', 'Sex']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocessor.set_output(transform='pandas')\n",
    "print('preprocessor created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a393a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined full pipelines\n"
     ]
    }
   ],
   "source": [
    "full_pipeline = Pipeline(steps=[\n",
    "    ('features_engineering', feature_engineering_pipeline),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "print('defined full pipelines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ff8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_raw.drop(['Survived'], axis=1)\n",
    "y = df_train_raw['Survived']\n",
    "X_test_final = df_test_raw.copy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5b9430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuadrícula de parámetros definida.\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "print(\"Cuadrícula de parámetros definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f8b5c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado!!\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Mejor modelo encontrado: Pipeline(steps=[('features_engineering',\n",
      "                 Pipeline(steps=[('get_title',\n",
      "                                  FunctionTransformer(func=<function get_title_from_name at 0x000002CA7AB26160>)),\n",
      "                                 ('classify_title',\n",
      "                                  FunctionTransformer(func=<function classify_titles at 0x000002CA7AB24860>)),\n",
      "                                 ('get_deck',\n",
      "                                  FunctionTransformer(func=<function get_deck_from_cabin at 0x000002CA2D76F240>)),\n",
      "                                 ('get_agency',\n",
      "                                  FunctionTr...\n",
      "                                                  ['Age', 'Fare',\n",
      "                                                   'TicketNumber', 'FamilySize',\n",
      "                                                   'Pclass', 'Title']),\n",
      "                                                 ('categorical',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(drop='first',\n",
      "                                                                                 handle_unknown='ignore',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['Embarked', 'Deck', 'Agency',\n",
      "                                                   'Sex'])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(max_depth=10, min_samples_split=5,\n",
      "                                        random_state=42))])\n",
      "Grid Search completado!\n"
     ]
    }
   ],
   "source": [
    "#Entrenar el modelo\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "print('Modelo entrenado!!')\n",
    "\n",
    "#Probar diferentes hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=full_pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "search_model = grid_search.fit(X_train, y_train)\n",
    "best_model = search_model.best_estimator_\n",
    "print(f'Mejor modelo encontrado: {best_model}')\n",
    "print('Grid Search completado!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ecc140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones realizadas en el conjunto de validación!\n",
      "Accuracy del modelo: 0.8045\n",
      "----------------------------------------\n",
      "Confussion Matrix:\n",
      "[[97 13]\n",
      " [22 47]]\n",
      "----------------------------------------\n",
      "response de clasificacion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       110\n",
      "           1       0.78      0.68      0.73        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.78      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albeiro Lozano\\Desktop\\PROJECTS\\titanic-survival\\titanic-survival\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\" y_pred_val = full_pipeline.predict(X_val) \"\"\"\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "print('Predicciones realizadas en el conjunto de validación!')\n",
    "res_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "print(f'Accuracy del modelo: {res_accuracy:.4f}')\n",
    "print('--' * 20)\n",
    "print('Confussion Matrix:')\n",
    "print(confusion_matrix(y_val, y_pred_val))\n",
    "print('--' * 20)\n",
    "print('response de clasificacion:')\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print('--' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a19e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submisión guardada en ../data/processed/submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Albeiro Lozano\\Desktop\\PROJECTS\\titanic-survival\\titanic-survival\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = best_model.predict(df_test_raw)\n",
    "subimission = pd.DataFrame({\n",
    "    'PassengerId': df_test_raw['PassengerId'],\n",
    "    'Survived': res\n",
    "})\n",
    "subimission.to_csv('../data/result/submission.csv', index=False)\n",
    "print('Submisión guardada en ../data/processed/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51d9a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado!!\n"
     ]
    }
   ],
   "source": [
    "jl.dump(best_model, open('../models/best_model.pkl', 'wb'))\n",
    "print('Modelo guardado!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
