{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Importar Librerías Esenciales ---\n",
    "\n",
    "# Librerías para manipulación de datos\n",
    "import pandas as pd\n",
    "# Uso: Fundamental para manejar DataFrames (tus tablas de datos).\n",
    "#      Se usará para cargar los CSV, manipular columnas, etc.\n",
    "\n",
    "import numpy as np\n",
    "# Uso: Para operaciones numéricas eficientes, especialmente con arrays de números.\n",
    "#      Scikit-learn trabaja mucho con arrays de NumPy internamente.\n",
    "\n",
    "import re\n",
    "# Uso: Para expresiones regulares. Necesario para la función de extracción de 'Title' del nombre\n",
    "#      y también para extraer el 'Ticket_Prefix' del número de billete.\n",
    "\n",
    "# Módulos de Scikit-learn para la construcción del Pipeline y Modelado\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# train_test_split: Para dividir el dataset en conjuntos de entrenamiento y validación.\n",
    "# Uso: Asegura que el modelo se evalúe en datos no vistos durante el entrenamiento.\n",
    "# GridSearchCV: Para la optimización de hiperparámetros de nuestro modelo y/o pipeline.\n",
    "# Uso: Busca sistemáticamente la mejor combinación de parámetros.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "# StandardScaler: Para estandarizar (escalar) las características numéricas.\n",
    "# Uso: Transforma los datos para que tengan media 0 y desviación estándar 1, útil para muchos algoritmos.\n",
    "# OneHotEncoder: Para convertir características categóricas (como 'Sex', 'Embarked') a formato numérico binario.\n",
    "# Uso: Permite que los modelos de ML trabajen con datos categóricos.\n",
    "# FunctionTransformer: Para integrar funciones personalizadas (como tus funciones de ingeniería de características)\n",
    "# Uso: Te permite usar tus funciones Python dentro del pipeline de Scikit-learn.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Uso: Para manejar los valores faltantes. Por ejemplo, rellenar 'Age' o 'Fare' con la media.\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Uso: Permite aplicar diferentes transformaciones a diferentes columnas del DataFrame.\n",
    "#      Es clave para nuestro pipeline, ya que tenemos columnas numéricas y categóricas.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Uso: La clase principal para construir tu pipeline. Encadena todos los pasos de preprocesamiento y el modelo.\n",
    "#      Esto garantiza que todas las transformaciones se apliquen consistentemente.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Uso: El algoritmo de Machine Learning que usaremos para nuestro modelo de clasificación binaria.\n",
    "#      Es un clasificador de conjunto robusto y de alto rendimiento.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# Uso: Para evaluar el rendimiento de nuestro modelo.\n",
    "# accuracy_score: La métrica principal para el concurso de Kaggle.\n",
    "# confusion_matrix: Muestra la cantidad de verdaderos positivos, negativos, falsos positivos y negativos.\n",
    "# classification_report: Proporciona precisión (precision), recall (sensibilidad) y F1-score por clase.\n",
    "\n",
    "# Librerías para visualización de datos (aunque en este notebook será más para mostrar resultados)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Uso: Para crear gráficos, como la matriz de confusión, para visualizar y entender los resultados del modelo.\n",
    "\n",
    "# Configuración para gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "# Uso: Ajustes estéticos para que los gráficos se vean bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a398f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a001c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv('../data/raw/train.csv')\n",
    "df_test_raw = pd.read_csv('../data/raw/test.csv')\n",
    "df_join_raw = pd.concat([df_train_raw.drop('Survived', axis=1), df_test_raw], ignore_index=True)\n",
    "temp_df = df_join_raw.copy()\n",
    "print(f'Dimensiones iniciales: {df_join_raw.shape}')\n",
    "print(f'Columnas iniciales: {df_join_raw.columns.to_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d5eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_title_from_name(df):\n",
    "    df = df.copy()\n",
    "    def extract_title(name):\n",
    "        title_extracted = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        if title_extracted:\n",
    "            return title_extracted.group(1)\n",
    "        return 'rare'\n",
    "    df['Title'] = df['Name'].apply(extract_title)\n",
    "    df = df.drop('Name', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_deck_from_cabin(df):\n",
    "    df = df.copy()\n",
    "    df['Cabin'] = df['Cabin'].fillna('Unknown')\n",
    "    df['Deck'] = df['Cabin'].transform(lambda x: x[0])\n",
    "    df = df.drop('Cabin', axis=1)\n",
    "    return df\n",
    "\n",
    "def get_agency_ticket_numbers_from_ticket(df):\n",
    "    df = df.copy()\n",
    "    def extract_prefix(ticket):\n",
    "        prefix_extracted = re.match(r'([A-Za-z\\./]+)', ticket)\n",
    "        if prefix_extracted:\n",
    "            return prefix_extracted.group(1).replace('.', '').replace('/', '').upper()\n",
    "        return 'NO_AGENCY'\n",
    "    df['Agency'] = df['Ticket'].apply(extract_prefix)\n",
    "    ticket_counts = df['Ticket'].value_counts()\n",
    "    df['TicketNumber'] = df['Ticket'].map(ticket_counts)\n",
    "    df = df.drop('Ticket', axis=1)\n",
    "    return df\n",
    "\n",
    "def familysize_isAlone_from_sibsp_parch(df):\n",
    "    df = df.copy()\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df = df.drop(['Parch', 'SibSp'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "feature_engineering_pipeline = Pipeline([\n",
    "    ('get_title', FunctionTransformer(get_title_from_name, validate=False)),\n",
    "    ('get_deck', FunctionTransformer(get_deck_from_cabin, validate=False)),\n",
    "    ('get_agency', FunctionTransformer(get_agency_ticket_numbers_from_ticket, validate=False)),\n",
    "    ('FamilySize', FunctionTransformer(familysize_isAlone_from_sibsp_parch, validate=False))\n",
    "])\n",
    "print('Cargado transformadores de ingenieria de features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ac4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorgize_ticket_class(matrix_feature):\n",
    "    temp_df = pd.DataFrame(matrix_feature, columns=['Pclass'])\n",
    "    def condition_class(ticket_class):\n",
    "        class_mapping = { 1: 2,  2: 1, 3: 0}\n",
    "        return class_mapping.get(ticket_class, 0)\n",
    "    temp_df['Pclass'] = temp_df['Pclass'].apply(condition_class)\n",
    "    return temp_df['Pclass'].values.reshape(-1,1)\n",
    "    \n",
    "    \n",
    "\n",
    "def age_imputed_from_title_pclass(matrix_features):\n",
    "    temp_df = pd.DataFrame(matrix_features, columns=['Age', 'Pclass', 'Title'])\n",
    "    temp_df['Age'] = temp_df.groupby(['Pclass', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    temp_df['Age'] = temp_df['Age'].fillna(temp_df['Age'].median())\n",
    "    return temp_df['Age'].values.reshape(-1,1)\n",
    "\n",
    "    \n",
    "print('Cargado imputadores numericos y categoricos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Pclass', 'Age', 'Fare', 'TicketNumber', 'FamilySize']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "numeric_transformer.set_output(transform=\"pandas\")\n",
    "\n",
    "categorical_features = ['Embarked', 'Title', 'Deck', 'Agency', 'Sex']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "categorical_transformer.set_output(transform=\"pandas\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('custom_imputer_age', FunctionTransformer(age_imputed_from_title_pclass), ['Age', 'Pclass', 'Title']),\n",
    "        ('custom_reorganize_pclass', FunctionTransformer(reorgize_ticket_class), ['Pclass']),\n",
    "        ('numeric', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "print('preprocessor created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(steps=[\n",
    "    ('features_engineering', feature_engineering_pipeline),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "full_pipeline.set_output(transform=\"pandas\")\n",
    "print('defined full pipelines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_raw.drop(['Survived'], axis=1)\n",
    "y = df_train_raw['Survived']\n",
    "X_test_final = df_test_raw.copy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00277782",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_demos = full_pipeline.named_steps['features_engineering'].fit_transform(X_train)\n",
    "x_demos = full_pipeline.named_steps['preprocessor'].fit_transform(x_demos)\n",
    "print(x_demos.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(X_train, y_train)\n",
    "y_pred_val_pipeline = full_pipeline.predict(X_val)\n",
    "acurrancy_pipeline = accuracy_score(y_val, y_pred_val_pipeline)\n",
    "print(f'Accuracy en el conjunto de validacion {acurrancy_pipeline}')\n",
    "print(confusion_matrix(y_val, y_pred_val_pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_predictions = full_pipeline.predict(X_test_final)\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': df_test_raw['PassengerId'],\n",
    "    'Survived': final_test_predictions\n",
    "})\n",
    "submission_df.to_csv('../data/result/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
